Granularity and alignment
-------------------------

The Windows heap managers (all versions) have always guaranteed that the 
heap allocations have a start address that is 8-byte aligned and on 
64-bit platforms the alignment is 16-bytes. 

The granularity of heap allocations in 32-bit Windows is 8 bytes and 16 
bytes in 64-bit Windows. 

VirtualAlloc can't allocate less than one page (4KB or 8KB depending
on architecture). And because of the 64 KB allocation granularity, it
usually doesn't make sense to allocate blocks that are less than 64 KB
in size (if you VirtualAlloc one 4 KB page, you waste 60 KB of virtual
memory, which is a finite resource on 32 bit).


Speed
-----

The heap functions are faster than the virtual allocation functions for 
blocks smaller than 16 KB because they don't require a transition to 
kernel mode and because they use the fast LFH heap. For bigger blocks up 
to 512 KB new/malloc/HeapAlloc are sometimes faster but not always. For 
blocks of 512 KB or greater the heap functions call the virtual 
functions, so that the speed is roughly the same. The heap free operations
on 16 KB - 512 KB blocks (standard heap range) can be quite slow because
of heap coalescing which should "find" the neighbours, pull them out to
construct a larger block, and reinsert the larger block into the free list. 
Internally new and malloc call HeapAlloc, but the speed difference is 
negligible because the overhead is really small. 


CRT Heap vs. Process Heap
-------------------------

Prior to Visual C++ 2012, each CRT had its own heap, created via 
HeapCreate. In Visual C++ 2012, the CRT uses the process heap, obtained 
via GetProcessHeap. 


Heap behaviour depends from allocation size
-------------------------------------------

LFH heap is active up to 16 KB, from 16 KB to 512 KB the standard heap 
is used and above this value the VirtualAlloc function is called. 

   
LFH Heap
--------

Starting with Windows Vista the low-fragmentation heap (LFH) is enabled 
by default for the default heap and starting with Visual Studio 2010 it 
is enable by default for the CRT heap. 
Enabling the LFH disables look-aside lists. The LFH is not a separate 
heap. Instead, it is a policy that applications can enable for their 
heaps. When the LFH is enabled, the system allocates memory in certain 
predetermined sizes. When an application requests a memory allocation 
from a heap that has the LFH enabled, the system allocates the smallest 
block of memory that is large enough to contain the requested size. The 
system does not use the LFH for allocations larger than 16 KB, whether 
or not the LFH is enabled. For memory blocks that are larger than 16 KB, 
the LFH uses the standard heap. 

The LFH avoids fragmentation by managing all allocated blocks in 128 
predetermined different block-size ranges. Each of the 128 size ranges 
is called a bucket. When an application needs to allocate memory from 
the heap, the LFH chooses the bucket that can allocate the smallest 
block large enough to contain the requested size. The smallest block 
that can be allocated is 8 bytes. 

The size ranges provided by the buckets are described in the following
table:

Buckets 	Granularity 	Range
1-32        8               1-256
33-48       16              257-512
49-64       32              513-1024
65-80       64              1025-2048
81-96       128             2049-4096
97-112      256             4097-8192
113-128     512             8193-16384

The first bucket is used for allocations between 1 and 8 bytes in size. 
The next bucket is used for allocations between 9 and 16 bytes in size, 
and so on until the 32nd bucket, which is used for allocations between 
249 and 256 bytes in size. The 33rd bucket is used for allocations 
between 257 and 272 bytes in size. The 34th bucket is used for 
allocations between 273 and 288 bytes in size, and so on. The final 
bucket (128th) is used for allocations between 15,873 and 16,384 bytes 
in size. 

For example, if an application needs to allocate 10 bytes of memory, the 
smallest block size that can accommodate this request is 16 bytes. 
Bucket two is used for allocations that are 16 bytes in size, therefore, 
the LFH will allocate the memory from bucket two. 

If the allocation is not a multiple of eight, there will be unused 
bytes. This is another form of fragmentation called internal 
fragmentation. The LFH was designed to balance internal and external 
fragmentation. 


Look-Aside Heap
---------------

A look-aside list is a fast memory allocation mechanism that contains 
only fixed-sized blocks. Look-aside lists are enabled by default for 
heaps that support them. Starting with Windows Vista, look-aside lists 
are not used and the LFH is enabled by default. Look-aside lists are 
faster than general pool allocations that vary in size, because the 
system does not search for free memory that fits the allocation. In 
addition, access to look-aside lists is generally synchronized using 
fast atomic processor exchange instructions instead of mutexes or 
spinlocks. Look-aside lists can be created by the system or drivers. 
They can be allocated from paged or nonpaged pool. 


Fixed and growing Heaps
-----------------------

If dwMaximumSize in HeapCreate is not zero, the heap size is fixed and 
cannot grow beyond the maximum size. Also, the largest memory block that 
can be allocated from the heap is slightly less than 512 KB for a 32-bit 
process and slightly less than 1024 KB for a 64-bit process. Requests 
to allocate larger blocks fail, even if the maximum size of the heap is 
large enough to contain the block. 

If dwMaximumSize is 0, the heap can grow in size. The heap's size is 
limited only by the available memory. Requests to allocate memory blocks 
larger than the limit for a fixed-size heap do not automatically fail; 
instead, the system calls the VirtualAlloc function to obtain the memory 
that is needed for large blocks. Applications that need to allocate 
large memory blocks should set dwMaximumSize to 0. The heap uncommits
freed blocks, but address space is still reserved, heap may eat up all
the address space if many large blocks are allocated (like 500 KB) and
freed.


Reference
---------

https://msdn.microsoft.com/en-us/library/ms810466.aspx
http://library.softwareverify.com/memory-fragmentation-your-worst-nightmare/


GetDIBits, SetDIBits, CreateDIBitmap, StretchDIBits, ... need VirtualAlloc
--------------------------------------------------------------------------

The buffer pointed to by lpvBits cannot straddle multiple virtual memory 
allocations. We have observed this on many different computers with 
different video cards and versions of Windows. 

The only safe buffer to pass to lpvBits is one that you have directly 
allocated using a single call to VirtualAlloc, never use heap functions! 

For example, the following procedure would fail:

1. Call VirtualAlloc and reserve/commit a 1 megabyte buffer.
2. Call VirtualAlloc and reserve/commit a second 1 megabyte buffer
   with a base address that immediately follows the allocation from #1.
3. Logically, we can now consider the base address for the first
   allocation to point to a 2 megabyte buffer, because the two commits
   were adjacent to each other (heap memory managers do exactly this).
4. Call GetDIBits for a 1.5 megabyte bitmap with lpvBits base address
   of first commit. The call fails, GetLastError() does not provide any
   clues. It turns out that the reason it fails is because the buffer
   pointed to by lpvBits straddles two VirtualAlloc reservations.
   The solution is to combine the two VirtualAlloc calls into a single
   VirtualAlloc call that reserves/commits the required buffer space.

I do not know why this problem occurs, it could be defined/due to 
any of these factors:

* The GDI function has an undocumented requirement for lpvBits to not 
  straddle multiple VirtualAlloc reserve/commits (i.e. this behavior
  is by design). 

* The GDI function has a bug where it can't handle buffers that straddle 
  multiple memory commits when it should be able to. 

* The video drivers on the system have a bug such that they impose this 
  undocumented requirement (i.e. not Microsoft's fault). It would be
  nice if someone at Microsoft could shed some light on this issue. 
  
From:
https://msdn.microsoft.com/en-us/library/windows/desktop/dd144879%28v=vs.85%29.aspx
https://groups.google.com/forum/#!msg/google-perftools/eb50K0c0RBo/u0uYQFa3Vm0J
https://code.google.com/p/gperftools/issues/detail?id=120&can=1&start=100


